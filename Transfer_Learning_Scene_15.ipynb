{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_Learning_Scene-15.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbosl31KFxyT"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import keras\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D,BatchNormalization, MaxPooling2D\n",
        "from keras.preprocessing.image import img_to_array, load_img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iTyu4E0FzfG"
      },
      "source": [
        "# Create Dataset\n",
        "\n",
        "def create_data(data_dir,class_folder):\n",
        "  directory = data_dir + \"/\" + class_folder + \"/\"\n",
        "  data = os.listdir(directory)\n",
        "  random.shuffle(data)\n",
        "  train = data[:100]\n",
        "  test = data[100:]\n",
        "\n",
        "  return train,test\n",
        "\n",
        "class_folder = []\n",
        "path = \"/content/drive/MyDrive/Dataset/15-Scene/15-Scene\"\n",
        "\n",
        "for category in sorted(os.listdir(path)):\n",
        "  class_folder.append(category)\n",
        "\n",
        "train_set = []\n",
        "test_set = []\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/Dataset/15-Scene/15-Scene'\n",
        "\n",
        "for class_name in class_folder:\n",
        "  train,test = create_data(data_dir,class_name)\n",
        "  train_data = [class_name,train]\n",
        "  test_data = [class_name,test]\n",
        "  train_set.append(train_data)\n",
        "  test_set.append(test_data)\n",
        "\n",
        "train_set = np.array(train_set,dtype=object)\n",
        "test_set = np.array(test_set,dtype=object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ghotrK6tF1AM",
        "outputId": "deb0122e-a358-42df-e8e6-5f345911da58"
      },
      "source": [
        "# Create directory to store train and test folder\n",
        "\n",
        "create_dir = \"/content/drive/MyDrive/Dataset/Train_Test\"\n",
        "output_directory = os.mkdir(os.path.join(create_dir,'Scene15_Output'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-59d2c8c65555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcreate_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Dataset/Train_Test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Scene15_Output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/Dataset/Train_Test/Scene15_Output'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "mWw-gg89F3V1",
        "outputId": "2a65c0b7-3950-46f6-e3df-601f532f13e5"
      },
      "source": [
        "def write_img_to_folder(data_dir,output_path,output_directory,folder_name,dataset):\n",
        "\n",
        "  new_folder = os.mkdir(os.path.join(output_directory,folder_name))\n",
        "\n",
        "  for data in dataset:\n",
        "    class_name = data[0]\n",
        "    data_files = data[1]\n",
        "\n",
        "    data_path = os.path.join(output_path + \"/\" + str(folder_name) ,class_name)\n",
        "    category_dire = os.mkdir(data_path)\n",
        "\n",
        "    for filename in data_files:\n",
        "      img = cv2.imread(data_dir + \"/\" + class_name + \"/\" + filename, 0)\n",
        "      cv2.imwrite(os.path.join(data_path, filename), img)\n",
        "\n",
        "output_path = \"/content/drive/MyDrive/Dataset/Train_Test/Scene15_Output\"\n",
        "output_directory = \"/content/drive/MyDrive/Dataset/Train_Test/Scene15_Output\"\n",
        "\n",
        "# Train/Test folder using write_img_to_folder function\n",
        "\n",
        "train_folder = write_img_to_folder(data_dir,output_path,output_directory,'Train', train_set)\n",
        "test_folder = write_img_to_folder(data_dir, output_path,output_directory,'Test', test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f01eee37b13a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Train/Test folder using write_img_to_folder function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrain_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite_img_to_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mtest_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite_img_to_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-f01eee37b13a>\u001b[0m in \u001b[0;36mwrite_img_to_folder\u001b[0;34m(data_dir, output_path, output_directory, folder_name, dataset)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrite_img_to_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mnew_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/Dataset/Train_Test/Scene15_Output/Train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm4zEjOwF6gE"
      },
      "source": [
        "def convert_img_to_array(dir_path):\n",
        "    X = []\n",
        "    y = []\n",
        "    one_hot_lookups = np.eye(15)\n",
        "\n",
        "    for category in sorted(os.listdir(dir_path)):\n",
        "\n",
        "      for files in os.listdir(dir_path + category):\n",
        "\n",
        "        img = load_img(dir_path + category + '/' + files,target_size=(224, 224))\n",
        "        #img = cv2.resize(img, dsize = (227,227))\n",
        "        img = img_to_array(img) \n",
        "        img = tf.image.per_image_standardization(img)  \n",
        "        X.append(img) \n",
        "        y.append(np.reshape(one_hot_lookups[int(category)],[15]))  \n",
        "\n",
        "    return X,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqUl5vQlF9X8",
        "outputId": "ba8f93d7-9a8e-4036-809e-407f80cfc122"
      },
      "source": [
        "def load_data():\n",
        "    train_dir_path = \"/content/drive/MyDrive/Dataset/Train_Test/Scene15_Output/Train/\"\n",
        "    X_train,y_train = convert_img_to_array(train_dir_path)\n",
        "    \n",
        "    test_dir_path = \"/content/drive/MyDrive/Dataset/Train_Test/Scene15_Output/Test/\"\n",
        "    X_test, y_test = convert_img_to_array(test_dir_path)\n",
        "    \n",
        "    X_train = np.asarray(X_train)\n",
        "    X_test = np.asarray(X_test)\n",
        "    y_train = np.asarray(y_train)\n",
        "    y_test = np.asarray(y_test)\n",
        "    \n",
        "    X_train /= np.std(X_train, axis = 0)\n",
        "    X_test /= np.std(X_test, axis = 0)\n",
        "    \n",
        "    return ((X_train, y_train), (X_test, y_test))\n",
        "(x_train, y_train), (x_test, y_test) = load_data()\n",
        "\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1500, 224, 224, 3)\n",
            "(1500, 15)\n",
            "(2985, 224, 224, 3)\n",
            "(2985, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poQUhmqWF_jI"
      },
      "source": [
        "model = Sequential()\n",
        "# 1st layer..........\n",
        "model.add(Conv2D(96, kernel_size = (11, 11), strides = (4,4), activation='relu', padding = 'valid' , data_format='channels_last', input_shape=(224, 224, 3),name = \"first\"))\n",
        "model.add(MaxPooling2D(pool_size=(3,3) , strides = (2,2) , padding = 'valid' )) \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd layer................\n",
        "model.add(Conv2D(256, kernel_size=(5,5), activation='relu', strides=(1,1), padding = 'valid', name = \"second\"))\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#3rd layer.................\n",
        "model.add(Conv2D(384, kernel_size=(3,3), activation='relu', strides=(1,1), padding='valid', name = \"third\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#4th layer.................\n",
        "model.add(Conv2D(384, kernel_size=(3,3), activation='relu', strides=(1,1), padding='valid', name = \"fourth\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#5th layer.................\n",
        "model.add(Conv2D(256, kernel_size=(3,3), strides=(1,1), activation = 'relu', padding='valid' , name = \"fifth\"))\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully Connected Layer 1\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Fully Connected Layer 2\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(15, activation = 'softmax')) #As number of nodes in last layer in softmax is number of classes, where each node is probability of classes\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "optimizer = SGD(learning_rate = 1e-3,momentum = 0.9)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Dg03bMGBtw",
        "outputId": "f2ea6170-e5f6-4a94-9815-fdc3452e34ce"
      },
      "source": [
        "print(model.get_layer(\"second\").get_weights()[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 5, 96, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8g06uv6MHCr"
      },
      "source": [
        "import numpy as np\n",
        "weights_dic = np.load('/content/drive/MyDrive/Dataset/bvlc_alexnet.npy', encoding='bytes',allow_pickle=True).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUA9rxudGDmf"
      },
      "source": [
        "model.get_layer(\"first\").set_weights([weights_dic[\"conv1\"][0], weights_dic[\"conv1\"][1]])\n",
        "# model.get_layer(\"second\").set_weights([weights_dic[\"conv2\"][0], weights_dic[\"conv2\"][1]])\n",
        "# model.get_layer(\"third\").set_weights([weights_dic[\"conv3\"][0], weights_dic[\"conv3\"][1]])\n",
        "# model.get_layer(\"fourth\").set_weights([weights_dic[\"conv4\"][0], weights_dic[\"conv4\"][1]])\n",
        "# model.get_layer(\"fifth\").set_weights([weights_dic[\"conv5\"][0], weights_dic[\"conv5\"][1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj7hc0ojGFFj",
        "outputId": "972c9a5b-950d-423a-a3e2-168432536620"
      },
      "source": [
        "from time import time\n",
        "tensorboard = keras.callbacks.TensorBoard(log_dir=\"pretrainedLogs/{}\".format(time()), histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "iter_1 = model.fit(x_train,y_train,validation_data = (x_test, y_test), epochs = 25, verbose = 1,callbacks=[tensorboard])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "47/47 [==============================] - 167s 4s/step - loss: 2.5820 - accuracy: 0.2667 - val_loss: 7.1001 - val_accuracy: 0.1725\n",
            "Epoch 2/25\n",
            "47/47 [==============================] - 192s 4s/step - loss: 1.7787 - accuracy: 0.4420 - val_loss: 3.6648 - val_accuracy: 0.3551\n",
            "Epoch 3/25\n",
            "47/47 [==============================] - 193s 4s/step - loss: 1.4510 - accuracy: 0.5167 - val_loss: 2.6940 - val_accuracy: 0.4379\n",
            "Epoch 4/25\n",
            "47/47 [==============================] - 194s 4s/step - loss: 1.3043 - accuracy: 0.5767 - val_loss: 1.9531 - val_accuracy: 0.5116\n",
            "Epoch 5/25\n",
            "47/47 [==============================] - 192s 4s/step - loss: 1.2488 - accuracy: 0.5880 - val_loss: 3.0479 - val_accuracy: 0.3876\n",
            "Epoch 6/25\n",
            "47/47 [==============================] - 164s 4s/step - loss: 1.1142 - accuracy: 0.6327 - val_loss: 2.2275 - val_accuracy: 0.4817\n",
            "Epoch 7/25\n",
            "47/47 [==============================] - 165s 4s/step - loss: 1.0106 - accuracy: 0.6767 - val_loss: 1.6596 - val_accuracy: 0.5685\n",
            "Epoch 8/25\n",
            "47/47 [==============================] - 164s 4s/step - loss: 0.9751 - accuracy: 0.6840 - val_loss: 2.2396 - val_accuracy: 0.4787\n",
            "Epoch 9/25\n",
            "47/47 [==============================] - 165s 4s/step - loss: 0.9039 - accuracy: 0.7153 - val_loss: 1.7411 - val_accuracy: 0.5655\n",
            "Epoch 10/25\n",
            "47/47 [==============================] - 193s 4s/step - loss: 0.7959 - accuracy: 0.7367 - val_loss: 1.6277 - val_accuracy: 0.5826\n",
            "Epoch 11/25\n",
            "47/47 [==============================] - 166s 4s/step - loss: 0.7410 - accuracy: 0.7673 - val_loss: 1.9395 - val_accuracy: 0.5323\n",
            "Epoch 12/25\n",
            "47/47 [==============================] - 193s 4s/step - loss: 0.7050 - accuracy: 0.7707 - val_loss: 1.9102 - val_accuracy: 0.5625\n",
            "Epoch 13/25\n",
            "47/47 [==============================] - 194s 4s/step - loss: 0.6818 - accuracy: 0.7693 - val_loss: 2.0092 - val_accuracy: 0.5645\n",
            "Epoch 14/25\n",
            "47/47 [==============================] - 194s 4s/step - loss: 0.6771 - accuracy: 0.7940 - val_loss: 2.1598 - val_accuracy: 0.5511\n",
            "Epoch 15/25\n",
            "47/47 [==============================] - 166s 4s/step - loss: 0.6237 - accuracy: 0.8040 - val_loss: 2.2109 - val_accuracy: 0.5092\n",
            "Epoch 16/25\n",
            "47/47 [==============================] - 166s 4s/step - loss: 0.6419 - accuracy: 0.8067 - val_loss: 1.8577 - val_accuracy: 0.5786\n",
            "Epoch 17/25\n",
            "47/47 [==============================] - 166s 4s/step - loss: 0.5136 - accuracy: 0.8380 - val_loss: 1.7100 - val_accuracy: 0.6050\n",
            "Epoch 18/25\n",
            "47/47 [==============================] - 194s 4s/step - loss: 0.4376 - accuracy: 0.8633 - val_loss: 1.7696 - val_accuracy: 0.6064\n",
            "Epoch 19/25\n",
            "47/47 [==============================] - 195s 4s/step - loss: 0.4469 - accuracy: 0.8540 - val_loss: 2.0313 - val_accuracy: 0.5752\n",
            "Epoch 20/25\n",
            "47/47 [==============================] - 195s 4s/step - loss: 0.5591 - accuracy: 0.8320 - val_loss: 2.8102 - val_accuracy: 0.4951\n",
            "Epoch 21/25\n",
            "47/47 [==============================] - 195s 4s/step - loss: 0.4553 - accuracy: 0.8647 - val_loss: 1.6875 - val_accuracy: 0.6188\n",
            "Epoch 22/25\n",
            "47/47 [==============================] - 168s 4s/step - loss: 0.4106 - accuracy: 0.8613 - val_loss: 1.8958 - val_accuracy: 0.5903\n",
            "Epoch 23/25\n",
            "47/47 [==============================] - 195s 4s/step - loss: 0.3373 - accuracy: 0.9000 - val_loss: 2.4747 - val_accuracy: 0.5273\n",
            "Epoch 24/25\n",
            "47/47 [==============================] - 195s 4s/step - loss: 0.3294 - accuracy: 0.9040 - val_loss: 2.3694 - val_accuracy: 0.5826\n",
            "Epoch 25/25\n",
            "47/47 [==============================] - 195s 4s/step - loss: 0.3527 - accuracy: 0.8940 - val_loss: 2.0244 - val_accuracy: 0.5980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1ab9429090>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unhRZcXYiAZ4"
      },
      "source": [
        "tensorboard = keras.callbacks.TensorBoard(log_dir=\"pretrainedLogs/{}\".format(time()), histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "iter_2 = model.fit(x_train,y_train,validation_data = (x_test, y_test), epochs = 10, verbose = 1,callbacks=[tensorboard], shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76qj5vFZiLrr"
      },
      "source": [
        "tensorboard = keras.callbacks.TensorBoard(log_dir=\"pretrainedLogs/{}\".format(time()), histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "iter_3 = model.fit(x_train,y_train,validation_data = (x_test, y_test), epochs = 10, verbose = 1,callbacks=[tensorboard], shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDwrhf0cGG5A"
      },
      "source": [
        "y_pred = model.predict(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wlB4cwCGIzH"
      },
      "source": [
        "print(\"Testing Accuracy: \",accuracy_score(y_test, y_pred) * 100, \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}