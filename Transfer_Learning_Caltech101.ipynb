{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_Caltech101.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBvBg4yWxScj"
      },
      "source": [
        "#import necessary Libraries\n",
        "%matplotlib inline\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D,BatchNormalization, MaxPooling2D\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import io\n",
        "import os\n",
        "import scipy.misc\n",
        "from keras.preprocessing import image\n",
        "from imageio import imread\n",
        "from keras import regularizers\n",
        "import csv\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "CnJ7Po9AxXNA",
        "outputId": "1a2484a6-f124-46cb-d129-c2c553ae6ec3"
      },
      "source": [
        "\n",
        "datasets_path = '/content/drive/MyDrive/Dataset/101_ObjectCategories' #Add the path to the dataset\n",
        "\n",
        "def load_images(path,n=0): \n",
        "    X = [] # intializae array\n",
        "    Y=[]\n",
        "    i=-1\n",
        "    labels = []\n",
        "    for label in os.listdir(path): #take folder name as a lable of imgaes froo given path's list of directory\n",
        "        back_path = os.path.join(path,label)\n",
        "        labels.append(label)  # stores lable in lables named array\n",
        "        i = i+1\n",
        "        for filename in os.listdir(back_path):  # for loop to take images from each folder from dataset\n",
        "            image_path = os.path.join(back_path,filename)  # image path\n",
        "            img = image.load_img(image_path,target_size=(128,128)) # using keras load_img function load image with size of 128*128\n",
        "            img = image.img_to_array(img) # convert image to array using keras img_to_array function it will give array 128*128*3\n",
        "            img[:,:,0] -= 123.68\n",
        "            img[:,:,1] -= 116.78\n",
        "            img[:,:,2] -= 103.94\n",
        "            \n",
        "            Y.append(i) # append lable count  in Y array\n",
        "            X.append(img) # appand converted image to araray in X array\n",
        "            \n",
        "    return X,Y,labels\n",
        "\n",
        "x_train,y,label_data = load_images(datasets_path) # call load_image function and store return value \n",
        "X = np.array(x_train) # convert into numpy array\n",
        "\n",
        "Y = np.array(y)\n",
        "print(X.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f33af0a006b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# call load_image function and store return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert into numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-f33af0a006b0>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(path, n)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#take folder name as a lable of imgaes froo given path's list of directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mback_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# stores lable in lables named array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Dataset/101_ObjectCategories'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f0LDfaMxaha"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25) # split dataset into train and test using train_test_split function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WGdRv1LxdKg"
      },
      "source": [
        "number_of_classes = 102 # number of classes in dataset\n",
        "Y_train = np_utils.to_categorical(y_train)\n",
        "Y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiKxzjn3xfN1"
      },
      "source": [
        "model = Sequential()\n",
        "# 1st layer..........\n",
        "model.add(Conv2D(96, kernel_size = (5, 5), strides = (2,2), activation='relu', padding = 'valid' , data_format='channels_last', input_shape=(128, 128, 3),name = \"first\"))\n",
        "model.add(MaxPooling2D(pool_size=(3,3) , strides = (2,2) , padding = 'valid' )) \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd layer................\n",
        "model.add(Conv2D(256, kernel_size=(3,3), activation='relu', strides=(1,1), padding = 'valid', name = \"second\"))\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#3rd layer.................\n",
        "model.add(Conv2D(384, kernel_size=(3,3), activation='relu', strides=(1,1), padding='valid', name = \"third\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#4th layer.................\n",
        "model.add(Conv2D(384, kernel_size=(3,3), activation='relu', strides=(1,1), padding='valid', name = \"fourth\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#5th layer.................\n",
        "model.add(Conv2D(256, kernel_size=(3,3), strides=(1,1), activation = 'relu', padding='valid' , name = \"fifth\"))\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully Connected Layer 1\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Fully Connected Layer 2\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(102, activation = 'softmax')) #As number of nodes in last layer in softmax is number of classes, where each node is probability of classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQRk76_LxhY8"
      },
      "source": [
        "# Compile the model\n",
        "optimizer = SGD(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, Y_train, batch_size=5, epochs=50, verbose=1, shuffle=True,validation_data=(X_test,Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMN8y_qoywXT"
      },
      "source": [
        "print(model.get_layer(\"second\").get_weights()[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKrg8QemyzYy"
      },
      "source": [
        "import numpy as np\n",
        "weights_dic = np.load('/content/drive/MyDrive/Dataset/bvlc_alexnet.npy', encoding='bytes',allow_pickle=True).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yEsaETZy2CA"
      },
      "source": [
        "model.get_layer(\"first\").set_weights([weights_dic[\"conv1\"][0], weights_dic[\"conv1\"][1]])\n",
        "# model.get_layer(\"second\").set_weights([weights_dic[\"conv2\"][0], weights_dic[\"conv2\"][1]])\n",
        "# model.get_layer(\"third\").set_weights([weights_dic[\"conv3\"][0], weights_dic[\"conv3\"][1]])\n",
        "# model.get_layer(\"fourth\").set_weights([weights_dic[\"conv4\"][0], weights_dic[\"conv4\"][1]])\n",
        "# model.get_layer(\"fifth\").set_weights([weights_dic[\"conv5\"][0], weights_dic[\"conv5\"][1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRYClZLyy3lk"
      },
      "source": [
        "from time import time\n",
        "tensorboard = keras.callbacks.TensorBoard(log_dir=\"pretrainedLogs/{}\".format(time()), histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "iter_1 = model.fit(x_train,y_train,validation_data = (x_test, y_test), epochs = 25, verbose = 1,callbacks=[tensorboard])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC0JwvfSy6tl"
      },
      "source": [
        "tensorboard = keras.callbacks.TensorBoard(log_dir=\"pretrainedLogs/{}\".format(time()), histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "iter_2 = model.fit(x_train,y_train,validation_data = (x_test, y_test), epochs = 10, verbose = 1,callbacks=[tensorboard], shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN-xReeyy8dp"
      },
      "source": [
        "tensorboard = keras.callbacks.TensorBoard(log_dir=\"pretrainedLogs/{}\".format(time()), histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "iter_3 = model.fit(x_train,y_train,validation_data = (x_test, y_test), epochs = 10, verbose = 1,callbacks=[tensorboard], shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNs8m5Pby9s3"
      },
      "source": [
        "y_pred = model.predict(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-DZ1EpXy_Kp"
      },
      "source": [
        "print(\"Testing Accuracy: \",accuracy_score(y_test, y_pred) * 100, \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}